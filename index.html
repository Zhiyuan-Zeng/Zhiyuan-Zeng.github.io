<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhiyuan Zeng</title>
  
  <meta name="author" content="Zhiyuan Zeng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhiyuan Zeng 曾致远</name>
              </p>
              <p>
                My name is Zhiyuan Zeng. I am a Ph.D. student (2024–present) at the Paul G. Allen School of Computer Science & Engineering, University of Washington, where I have the privilege of being advised by <a href="https://homes.cs.washington.edu/~hannaneh/">Prof. Hannaneh Hajishirzi</a> and <a href="https://koh.pw/">Prof. Pang Wei Koh</a>. I previously received my Bachelor of Engineering degree from the Department of Computer Science and Technology at Tsinghua University in June 2024. During my undergraduate years, I was fortunate to work with <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a> at Tsinghua University and <a href="https://www.cs.princeton.edu/~danqic/">Prof. Danqi Chen</a> at Princeton University.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhiyuan1zeng@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=qLJqCqsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/ZhiyuanZeng_">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Zhiyuan-Zeng">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img
                      style="width:80%;max-width:80%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <heading>Selected Papers</heading>
        <p>
          * denotes equal contribution
        </p>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top: -15px;"><tbody>

          <tr>
            <td style="padding:5px 20px;width:75%;vertical-align:middle">
                <papertitle>Evaluating Large Language Models at Evaluating Instruction Following</papertitle>
              </a>
                <br>
                <strong>Zhiyuan Zeng</strong>, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal, Danqi Chen
                <br>
                <i>ICLR 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2310.07641">[paper]</a><a href="https://github.com/princeton-nlp/LLMBar">[code]
            </td>
          </tr>
          
          <tr>
            <td style="padding:5px 20px;width:75%;vertical-align:middle">
                <papertitle>Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning</papertitle>
              </a>
                <br>
                Mengzhou Xia, Tianyu Gao, <strong>Zhiyuan Zeng</strong>, Danqi Chen
                <br>
                <i>ICLR 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2310.06694">[paper]</a><a href="https://github.com/princeton-nlp/LLM-Shearing">[code]<a href="https://xiamengzhou.github.io/sheared-llama">[blog]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:5px 20px;width:75%;vertical-align:middle">
                <papertitle>Emergent Modularity in Pre-trained Transformers</papertitle>
              </a>
                <br>
                Zhengyan Zhang*, <strong>Zhiyuan Zeng*</strong>, Yankai Lin, Chaojun Xiao, Xiaozhi Wang, Xu Han, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Jie Zhou
            <br>
                <i>Findings of ACL 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2305.18390">[paper]</a><a href="https://github.com/THUNLP/modularity-analysis">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:5px 20px;width:75%;vertical-align:middle">
                <papertitle>Plug-and-Play Knowledge Injection for Pre-trained Language Models</papertitle>
              </a>
                <br>
                Zhengyan Zhang*, <strong>Zhiyuan Zeng*</strong>, Yankai Lin, Huadong Wang, Deming Ye, Chaojun Xiao, Xu Han, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou
            <br>
                <i>ACL 2023</i>
            <br>
              <a href="https://arxiv.org/abs/2305.17691">[paper]</a><a href="https://github.com/THUNLP/Knowledge-Plugin">[code]</a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website design from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
